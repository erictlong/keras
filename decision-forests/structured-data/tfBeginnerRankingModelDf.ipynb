{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training a Ranking Model\n",
    "\n",
    "The goal of a ranking is to order item by importance. The value of relevance does not matter directly. \n",
    "\n",
    "Ranking a set of documents with regard to user query is an example of ranking problem. Its only important to ge tthe right order where the top documents matter more.\n",
    "\n",
    "The Revevance/label is a floating point numerical value between 0 and 5 (generally between 0 and 4) where 0 means \"completely unrelated\", 4 means \"very relevant\" and 5 means \"the same as the query\"\n",
    "\n",
    "url: https://en.wikipedia.org/wiki/Learning_to_rank\n",
    "url 2: https://www.tensorflow.org/decision_forests/tutorials/beginner_colab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow_decision_forests as tfdf\n",
    "\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "archive_path = tf.keras.utils.get_file(\"letor.zip\",\n",
    "  \"https://download.microsoft.com/download/E/7/E/E7EABEF1-4C7B-4E31-ACE5-73927950ED5E/Letor.zip\",\n",
    "  extract=True)\n",
    "\n",
    "# Path to the train and test dataset using libsvm format.\n",
    "raw_dataset_path = os.path.join(os.path.dirname(archive_path), \"../../dataset/Letor/OHSUMED/Data/All/OHSUMED.txt\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The dataset is stored as a .txt file in a specific format. We will need to convert it into a csv file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>relevance</th>\n",
       "      <th>group</th>\n",
       "      <th>f_1</th>\n",
       "      <th>f_2</th>\n",
       "      <th>f_3</th>\n",
       "      <th>f_4</th>\n",
       "      <th>f_5</th>\n",
       "      <th>f_6</th>\n",
       "      <th>f_7</th>\n",
       "      <th>f_8</th>\n",
       "      <th>...</th>\n",
       "      <th>f_16</th>\n",
       "      <th>f_17</th>\n",
       "      <th>f_18</th>\n",
       "      <th>f_19</th>\n",
       "      <th>f_20</th>\n",
       "      <th>f_21</th>\n",
       "      <th>f_22</th>\n",
       "      <th>f_23</th>\n",
       "      <th>f_24</th>\n",
       "      <th>f_25</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2</td>\n",
       "      <td>g_1</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.079442</td>\n",
       "      <td>0.272727</td>\n",
       "      <td>0.261034</td>\n",
       "      <td>37.330565</td>\n",
       "      <td>11.431241</td>\n",
       "      <td>37.29975</td>\n",
       "      <td>1.138657</td>\n",
       "      <td>...</td>\n",
       "      <td>9.340024</td>\n",
       "      <td>24.808785</td>\n",
       "      <td>0.393091</td>\n",
       "      <td>57.416517</td>\n",
       "      <td>3.294893</td>\n",
       "      <td>25.0231</td>\n",
       "      <td>3.219799</td>\n",
       "      <td>-3.87098</td>\n",
       "      <td>-3.90273</td>\n",
       "      <td>-3.87512</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>g_1</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.079442</td>\n",
       "      <td>0.428571</td>\n",
       "      <td>0.400594</td>\n",
       "      <td>37.330565</td>\n",
       "      <td>11.431241</td>\n",
       "      <td>37.29975</td>\n",
       "      <td>1.814480</td>\n",
       "      <td>...</td>\n",
       "      <td>9.340024</td>\n",
       "      <td>24.808785</td>\n",
       "      <td>0.349205</td>\n",
       "      <td>43.240626</td>\n",
       "      <td>2.654724</td>\n",
       "      <td>23.4903</td>\n",
       "      <td>3.156588</td>\n",
       "      <td>-3.96838</td>\n",
       "      <td>-4.00865</td>\n",
       "      <td>-3.98670</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>g_1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>37.330565</td>\n",
       "      <td>11.431241</td>\n",
       "      <td>37.29975</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>9.340024</td>\n",
       "      <td>24.808785</td>\n",
       "      <td>0.240319</td>\n",
       "      <td>25.816989</td>\n",
       "      <td>1.551342</td>\n",
       "      <td>15.8650</td>\n",
       "      <td>2.764115</td>\n",
       "      <td>-4.28166</td>\n",
       "      <td>-4.33313</td>\n",
       "      <td>-4.44161</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2</td>\n",
       "      <td>g_1</td>\n",
       "      <td>4.0</td>\n",
       "      <td>2.772589</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.320171</td>\n",
       "      <td>37.330565</td>\n",
       "      <td>11.431241</td>\n",
       "      <td>37.29975</td>\n",
       "      <td>1.260808</td>\n",
       "      <td>...</td>\n",
       "      <td>9.340024</td>\n",
       "      <td>24.808785</td>\n",
       "      <td>0.111496</td>\n",
       "      <td>10.092426</td>\n",
       "      <td>0.649758</td>\n",
       "      <td>14.2778</td>\n",
       "      <td>2.658706</td>\n",
       "      <td>-4.77772</td>\n",
       "      <td>-4.73563</td>\n",
       "      <td>-4.86759</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>g_1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>37.330565</td>\n",
       "      <td>11.431241</td>\n",
       "      <td>37.29975</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>9.340024</td>\n",
       "      <td>24.808785</td>\n",
       "      <td>0.182104</td>\n",
       "      <td>23.546296</td>\n",
       "      <td>1.621393</td>\n",
       "      <td>15.2764</td>\n",
       "      <td>2.726309</td>\n",
       "      <td>-4.43073</td>\n",
       "      <td>-4.45985</td>\n",
       "      <td>-4.57053</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 27 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   relevance group  f_1       f_2       f_3       f_4        f_5        f_6  \\\n",
       "0          2   g_1  3.0  2.079442  0.272727  0.261034  37.330565  11.431241   \n",
       "1          0   g_1  3.0  2.079442  0.428571  0.400594  37.330565  11.431241   \n",
       "2          2   g_1  0.0  0.000000  0.000000  0.000000  37.330565  11.431241   \n",
       "3          2   g_1  4.0  2.772589  0.333333  0.320171  37.330565  11.431241   \n",
       "4          0   g_1  0.0  0.000000  0.000000  0.000000  37.330565  11.431241   \n",
       "\n",
       "        f_7       f_8  ...      f_16       f_17      f_18       f_19  \\\n",
       "0  37.29975  1.138657  ...  9.340024  24.808785  0.393091  57.416517   \n",
       "1  37.29975  1.814480  ...  9.340024  24.808785  0.349205  43.240626   \n",
       "2  37.29975  0.000000  ...  9.340024  24.808785  0.240319  25.816989   \n",
       "3  37.29975  1.260808  ...  9.340024  24.808785  0.111496  10.092426   \n",
       "4  37.29975  0.000000  ...  9.340024  24.808785  0.182104  23.546296   \n",
       "\n",
       "       f_20     f_21      f_22     f_23     f_24     f_25  \n",
       "0  3.294893  25.0231  3.219799 -3.87098 -3.90273 -3.87512  \n",
       "1  2.654724  23.4903  3.156588 -3.96838 -4.00865 -3.98670  \n",
       "2  1.551342  15.8650  2.764115 -4.28166 -4.33313 -4.44161  \n",
       "3  0.649758  14.2778  2.658706 -4.77772 -4.73563 -4.86759  \n",
       "4  1.621393  15.2764  2.726309 -4.43073 -4.45985 -4.57053  \n",
       "\n",
       "[5 rows x 27 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def convert_libsvm_to_csv(src_path, dst_path):\n",
    "  \"\"\"Converts a libsvm ranking dataset into a flat csv file.\n",
    "\n",
    "  Note: This code is specific to the LETOR3 dataset.\n",
    "  \"\"\"\n",
    "  dst_handle = open(dst_path, \"w\")\n",
    "  first_line = True\n",
    "  for src_line in open(src_path,\"r\"):\n",
    "    # Note: The last 3 items are comments.\n",
    "    items = src_line.split(\" \")[:-3]\n",
    "    relevance = items[0]\n",
    "    group = items[1].split(\":\")[1]\n",
    "    features = [ item.split(\":\") for item in items[2:]]\n",
    "\n",
    "    if first_line:\n",
    "      # Csv header\n",
    "      dst_handle.write(\"relevance,group,\" + \",\".join([\"f_\" + feature[0] for feature in features]) + \"\\n\")\n",
    "      first_line = False\n",
    "    dst_handle.write(relevance + \",g_\" + group + \",\" + (\",\".join([feature[1] for feature in features])) + \"\\n\")\n",
    "  dst_handle.close()\n",
    "  \n",
    "# convert the dataset\n",
    "csv_dataset_path = \"../../dataset/ohsumed.csv\"\n",
    "convert_libsvm_to_csv(\"../../dataset/Letor/OHSUMED/Data/All/OHSUMED.txt\", csv_dataset_path)\n",
    "\n",
    "# load a dataset into pandas\n",
    "dataset_df = pd.read_csv(csv_dataset_path)\n",
    "\n",
    "# display the first 3 examples\n",
    "dataset_df.head()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11291 examples in training, 4849 examples for testing.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>relevance</th>\n",
       "      <th>group</th>\n",
       "      <th>f_1</th>\n",
       "      <th>f_2</th>\n",
       "      <th>f_3</th>\n",
       "      <th>f_4</th>\n",
       "      <th>f_5</th>\n",
       "      <th>f_6</th>\n",
       "      <th>f_7</th>\n",
       "      <th>f_8</th>\n",
       "      <th>...</th>\n",
       "      <th>f_16</th>\n",
       "      <th>f_17</th>\n",
       "      <th>f_18</th>\n",
       "      <th>f_19</th>\n",
       "      <th>f_20</th>\n",
       "      <th>f_21</th>\n",
       "      <th>f_22</th>\n",
       "      <th>f_23</th>\n",
       "      <th>f_24</th>\n",
       "      <th>f_25</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2</td>\n",
       "      <td>g_1</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.079442</td>\n",
       "      <td>0.272727</td>\n",
       "      <td>0.261034</td>\n",
       "      <td>37.330565</td>\n",
       "      <td>11.431241</td>\n",
       "      <td>37.29975</td>\n",
       "      <td>1.138657</td>\n",
       "      <td>...</td>\n",
       "      <td>9.340024</td>\n",
       "      <td>24.808785</td>\n",
       "      <td>0.393091</td>\n",
       "      <td>57.416517</td>\n",
       "      <td>3.294893</td>\n",
       "      <td>25.0231</td>\n",
       "      <td>3.219799</td>\n",
       "      <td>-3.87098</td>\n",
       "      <td>-3.90273</td>\n",
       "      <td>-3.87512</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>g_1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>37.330565</td>\n",
       "      <td>11.431241</td>\n",
       "      <td>37.29975</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>9.340024</td>\n",
       "      <td>24.808785</td>\n",
       "      <td>0.240319</td>\n",
       "      <td>25.816989</td>\n",
       "      <td>1.551342</td>\n",
       "      <td>15.8650</td>\n",
       "      <td>2.764115</td>\n",
       "      <td>-4.28166</td>\n",
       "      <td>-4.33313</td>\n",
       "      <td>-4.44161</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2</td>\n",
       "      <td>g_1</td>\n",
       "      <td>4.0</td>\n",
       "      <td>2.772589</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.320171</td>\n",
       "      <td>37.330565</td>\n",
       "      <td>11.431241</td>\n",
       "      <td>37.29975</td>\n",
       "      <td>1.260808</td>\n",
       "      <td>...</td>\n",
       "      <td>9.340024</td>\n",
       "      <td>24.808785</td>\n",
       "      <td>0.111496</td>\n",
       "      <td>10.092426</td>\n",
       "      <td>0.649758</td>\n",
       "      <td>14.2778</td>\n",
       "      <td>2.658706</td>\n",
       "      <td>-4.77772</td>\n",
       "      <td>-4.73563</td>\n",
       "      <td>-4.86759</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3 rows × 27 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   relevance group  f_1       f_2       f_3       f_4        f_5        f_6  \\\n",
       "0          2   g_1  3.0  2.079442  0.272727  0.261034  37.330565  11.431241   \n",
       "2          2   g_1  0.0  0.000000  0.000000  0.000000  37.330565  11.431241   \n",
       "3          2   g_1  4.0  2.772589  0.333333  0.320171  37.330565  11.431241   \n",
       "\n",
       "        f_7       f_8  ...      f_16       f_17      f_18       f_19  \\\n",
       "0  37.29975  1.138657  ...  9.340024  24.808785  0.393091  57.416517   \n",
       "2  37.29975  0.000000  ...  9.340024  24.808785  0.240319  25.816989   \n",
       "3  37.29975  1.260808  ...  9.340024  24.808785  0.111496  10.092426   \n",
       "\n",
       "       f_20     f_21      f_22     f_23     f_24     f_25  \n",
       "0  3.294893  25.0231  3.219799 -3.87098 -3.90273 -3.87512  \n",
       "2  1.551342  15.8650  2.764115 -4.28166 -4.33313 -4.44161  \n",
       "3  0.649758  14.2778  2.658706 -4.77772 -4.73563 -4.86759  \n",
       "\n",
       "[3 rows x 27 columns]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def split_dataset(dataset, test_ratio=0.30):\n",
    "    \"\"\"Split a panda dataframe in two\"\"\"\n",
    "    test_indices = np.random.rand(len(dataset)) < test_ratio\n",
    "    return dataset[~test_indices], dataset[test_indices]\n",
    "\n",
    "train_ds_pd, test_ds_pd = split_dataset(dataset_df)\n",
    "print(\"{} examples in training, {} examples for testing.\".format(\n",
    "    len(train_ds_pd), len(test_ds_pd)\n",
    "))\n",
    "\n",
    "# display the fist 3 examples of the training dataset\n",
    "train_ds_pd.head(3)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "in the dataset the relevance defines the ground truth rank among row of the same group"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Metal device set to: Apple M1\n",
      "\n",
      "systemMemory: 8.00 GB\n",
      "maxCacheSize: 2.67 GB\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/eric/keras-env/lib/python3.8/site-packages/tensorflow_decision_forests/keras/core_inference.py:873: FutureWarning: In a future version of pandas all arguments of DataFrame.drop except for the argument 'labels' will be keyword-only.\n",
      "  features_dataframe = dataframe.drop(label, 1)\n",
      "2022-12-24 20:59:15.862716: I tensorflow/core/common_runtime/pluggable_device/pluggable_device_factory.cc:306] Could not identify NUMA node of platform GPU ID 0, defaulting to 0. Your kernel may not have been built with NUMA support.\n",
      "2022-12-24 20:59:15.864376: I tensorflow/core/common_runtime/pluggable_device/pluggable_device_factory.cc:272] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 0 MB memory) -> physical PluggableDevice (device: 0, name: METAL, pci bus id: <undefined>)\n",
      "/Users/eric/keras-env/lib/python3.8/site-packages/tensorflow_decision_forests/keras/core_inference.py:873: FutureWarning: In a future version of pandas all arguments of DataFrame.drop except for the argument 'labels' will be keyword-only.\n",
      "  features_dataframe = dataframe.drop(label, 1)\n"
     ]
    }
   ],
   "source": [
    "# name of relevance and grouping columns\n",
    "relevance = \"relevance\"\n",
    "\n",
    "ranking_train_ds = tfdf.keras.pd_dataframe_to_tf_dataset(train_ds_pd, label=relevance, task=tfdf.keras.Task.RANKING)\n",
    "ranking_test_ds = tfdf.keras.pd_dataframe_to_tf_dataset(test_ds_pd, label=relevance, task=tfdf.keras.Task.RANKING)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Use /var/folders/sk/f7k402kx1wvdmcz91gdz6hs00000gn/T/tmptqd686s7 as temporary training directory\n",
      "Reading training dataset...\n",
      "Training dataset read in 0:00:01.934200. Found 11291 examples.\n",
      "Training model...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-12-24 21:00:38.131034: W tensorflow/core/platform/profile_utils/cpu_utils.cc:128] Failed to get CPU frequency: 0 Hz\n",
      "2022-12-24 21:00:38.132660: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:114] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model trained in 0:00:00.624182\n",
      "Compiling model...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[INFO kernel.cc:1176] Loading model from path /var/folders/sk/f7k402kx1wvdmcz91gdz6hs00000gn/T/tmptqd686s7/model/ with prefix d4805d9c6a7b4dbf\n",
      "[INFO abstract_model.cc:1249] Engine \"GradientBoostedTreesQuickScorerExtended\" built\n",
      "[INFO kernel.cc:1022] Use fast generic engine\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:AutoGraph could not transform <function simple_ml_inference_op_with_handle at 0x17a9174c0> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: could not get source code\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:AutoGraph could not transform <function simple_ml_inference_op_with_handle at 0x17a9174c0> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: could not get source code\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING: AutoGraph could not transform <function simple_ml_inference_op_with_handle at 0x17a9174c0> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: could not get source code\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "Model compiled.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-12-24 21:00:39.569869: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:114] Plugin optimizer for device_type GPU is enabled.\n",
      "2022-12-24 21:00:39.624401: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:114] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x17ab399d0>"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_8 = tfdf.keras.GradientBoostedTreesModel(\n",
    "    task=tfdf.keras.Task.RANKING,\n",
    "    ranking_group=\"group\",\n",
    "    num_trees=50\n",
    ")\n",
    "\n",
    "model_8.fit(x=ranking_train_ds)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "keras does not propose any ranking metrics. Instead the training and validation are shown in the training logs. In this case the loss is lambda_mart_ndcg5 and the fineal (ie at the end of the training) NDCG (normalized discounted cumulative gain) is 0.510136"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"gradient_boosted_trees_model\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      "=================================================================\n",
      "Total params: 1\n",
      "Trainable params: 0\n",
      "Non-trainable params: 1\n",
      "_________________________________________________________________\n",
      "Type: \"GRADIENT_BOOSTED_TREES\"\n",
      "Task: RANKING\n",
      "Label: \"__LABEL\"\n",
      "Rank group: \"__RANK_GROUP\"\n",
      "\n",
      "Input Features (25):\n",
      "\tf_1\n",
      "\tf_10\n",
      "\tf_11\n",
      "\tf_12\n",
      "\tf_13\n",
      "\tf_14\n",
      "\tf_15\n",
      "\tf_16\n",
      "\tf_17\n",
      "\tf_18\n",
      "\tf_19\n",
      "\tf_2\n",
      "\tf_20\n",
      "\tf_21\n",
      "\tf_22\n",
      "\tf_23\n",
      "\tf_24\n",
      "\tf_25\n",
      "\tf_3\n",
      "\tf_4\n",
      "\tf_5\n",
      "\tf_6\n",
      "\tf_7\n",
      "\tf_8\n",
      "\tf_9\n",
      "\n",
      "No weights\n",
      "\n",
      "Variable Importance: MEAN_MIN_DEPTH:\n",
      "    1. \"__RANK_GROUP\"  4.739620 ################\n",
      "    2.      \"__LABEL\"  4.739620 ################\n",
      "    3.         \"f_15\"  4.729743 ###############\n",
      "    4.          \"f_1\"  4.729553 ###############\n",
      "    5.         \"f_13\"  4.718252 ###############\n",
      "    6.         \"f_11\"  4.717208 ###############\n",
      "    7.         \"f_12\"  4.710133 ###############\n",
      "    8.         \"f_19\"  4.606778 ###############\n",
      "    9.          \"f_2\"  4.552160 ###############\n",
      "   10.          \"f_5\"  4.550066 ###############\n",
      "   11.          \"f_7\"  4.536138 ###############\n",
      "   12.         \"f_20\"  4.508410 ###############\n",
      "   13.         \"f_18\"  4.501252 ###############\n",
      "   14.          \"f_6\"  4.446892 ##############\n",
      "   15.         \"f_14\"  4.378453 ##############\n",
      "   16.         \"f_21\"  4.256597 #############\n",
      "   17.         \"f_22\"  4.242408 #############\n",
      "   18.         \"f_17\"  4.229698 #############\n",
      "   19.         \"f_23\"  4.222407 #############\n",
      "   20.          \"f_3\"  4.199150 #############\n",
      "   21.         \"f_24\"  4.182844 #############\n",
      "   22.         \"f_10\"  4.137139 #############\n",
      "   23.         \"f_16\"  4.136039 #############\n",
      "   24.          \"f_9\"  4.087999 #############\n",
      "   25.         \"f_25\"  3.901761 ############\n",
      "   26.          \"f_8\"  3.281035 #########\n",
      "   27.          \"f_4\"  0.877025 \n",
      "\n",
      "Variable Importance: NUM_AS_ROOT:\n",
      "    1.  \"f_4\" 12.000000 ################\n",
      "    2. \"f_14\"  1.000000 \n",
      "    3.  \"f_3\"  1.000000 \n",
      "    4.  \"f_8\"  1.000000 \n",
      "\n",
      "Variable Importance: NUM_NODES:\n",
      "    1.  \"f_8\" 33.000000 ################\n",
      "    2.  \"f_4\" 27.000000 ############\n",
      "    3. \"f_24\" 25.000000 ###########\n",
      "    4. \"f_16\" 21.000000 #########\n",
      "    5.  \"f_9\" 21.000000 #########\n",
      "    6. \"f_20\" 19.000000 ########\n",
      "    7. \"f_21\" 18.000000 ########\n",
      "    8. \"f_18\" 17.000000 #######\n",
      "    9. \"f_25\" 17.000000 #######\n",
      "   10. \"f_22\" 16.000000 #######\n",
      "   11.  \"f_6\" 15.000000 ######\n",
      "   12. \"f_23\" 14.000000 ######\n",
      "   13. \"f_10\" 13.000000 #####\n",
      "   14. \"f_17\" 13.000000 #####\n",
      "   15. \"f_19\" 11.000000 ####\n",
      "   16.  \"f_3\" 11.000000 ####\n",
      "   17.  \"f_5\" 11.000000 ####\n",
      "   18.  \"f_2\" 10.000000 ####\n",
      "   19. \"f_14\"  8.000000 ###\n",
      "   20.  \"f_7\"  5.000000 #\n",
      "   21. \"f_11\"  4.000000 #\n",
      "   22. \"f_12\"  4.000000 #\n",
      "   23. \"f_13\"  4.000000 #\n",
      "   24.  \"f_1\"  2.000000 \n",
      "   25. \"f_15\"  2.000000 \n",
      "\n",
      "Variable Importance: SUM_SCORE:\n",
      "    1.  \"f_4\" 6421.234918 ################\n",
      "    2.  \"f_8\" 3745.193657 #########\n",
      "    3. \"f_24\" 2323.461118 #####\n",
      "    4. \"f_22\" 2208.063606 #####\n",
      "    5. \"f_25\" 1982.861076 ####\n",
      "    6.  \"f_9\" 1917.530605 ####\n",
      "    7. \"f_16\" 1746.009029 ####\n",
      "    8.  \"f_3\" 1724.220593 ####\n",
      "    9.  \"f_6\" 1622.725481 ###\n",
      "   10. \"f_21\" 1506.602926 ###\n",
      "   11. \"f_20\" 1300.589714 ###\n",
      "   12. \"f_18\" 1274.033824 ###\n",
      "   13.  \"f_2\" 1248.566979 ###\n",
      "   14. \"f_17\" 1080.733427 ##\n",
      "   15. \"f_13\" 811.983743 #\n",
      "   16. \"f_23\" 619.113178 #\n",
      "   17. \"f_10\" 608.401502 #\n",
      "   18. \"f_14\" 587.253815 #\n",
      "   19.  \"f_5\" 545.618939 #\n",
      "   20.  \"f_7\" 327.641806 \n",
      "   21. \"f_19\" 321.000259 \n",
      "   22. \"f_15\" 172.384790 \n",
      "   23. \"f_11\" 99.263132 \n",
      "   24.  \"f_1\" 38.488276 \n",
      "   25. \"f_12\" 25.122718 \n",
      "\n",
      "\n",
      "\n",
      "Loss: LAMBDA_MART_NDCG5\n",
      "Validation loss value: -0.579028\n",
      "Number of trees per iteration: 1\n",
      "Node format: NOT_SET\n",
      "Number of trees: 15\n",
      "Total number of nodes: 697\n",
      "\n",
      "Number of nodes by tree:\n",
      "Count: 15 Average: 46.4667 StdDev: 7.31999\n",
      "Min: 25 Max: 53 Ignored: 0\n",
      "----------------------------------------------\n",
      "[ 25, 26) 1   6.67%   6.67% ###\n",
      "[ 26, 27) 0   0.00%   6.67%\n",
      "[ 27, 29) 0   0.00%   6.67%\n",
      "[ 29, 30) 0   0.00%   6.67%\n",
      "[ 30, 32) 0   0.00%   6.67%\n",
      "[ 32, 33) 0   0.00%   6.67%\n",
      "[ 33, 35) 0   0.00%   6.67%\n",
      "[ 35, 36) 1   6.67%  13.33% ###\n",
      "[ 36, 38) 0   0.00%  13.33%\n",
      "[ 38, 39) 0   0.00%  13.33%\n",
      "[ 39, 40) 0   0.00%  13.33%\n",
      "[ 40, 42) 0   0.00%  13.33%\n",
      "[ 42, 43) 0   0.00%  13.33%\n",
      "[ 43, 45) 1   6.67%  20.00% ###\n",
      "[ 45, 46) 1   6.67%  26.67% ###\n",
      "[ 46, 48) 4  26.67%  53.33% ##########\n",
      "[ 48, 49) 0   0.00%  53.33%\n",
      "[ 49, 51) 1   6.67%  60.00% ###\n",
      "[ 51, 52) 3  20.00%  80.00% ########\n",
      "[ 52, 53] 3  20.00% 100.00% ########\n",
      "\n",
      "Depth by leafs:\n",
      "Count: 356 Average: 4.75562 StdDev: 0.594305\n",
      "Min: 1 Max: 5 Ignored: 0\n",
      "----------------------------------------------\n",
      "[ 1, 2)   1   0.28%   0.28%\n",
      "[ 2, 3)   2   0.56%   0.84%\n",
      "[ 3, 4)  18   5.06%   5.90% #\n",
      "[ 4, 5)  41  11.52%  17.42% #\n",
      "[ 5, 5] 294  82.58% 100.00% ##########\n",
      "\n",
      "Number of training obs by leaf:\n",
      "Count: 356 Average: 432.008 StdDev: 1627.92\n",
      "Min: 5 Max: 9792 Ignored: 0\n",
      "----------------------------------------------\n",
      "[    5,  494) 322  90.45%  90.45% ##########\n",
      "[  494,  983)   9   2.53%  92.98%\n",
      "[  983, 1473)   0   0.00%  92.98%\n",
      "[ 1473, 1962)   3   0.84%  93.82%\n",
      "[ 1962, 2452)   3   0.84%  94.66%\n",
      "[ 2452, 2941)   4   1.12%  95.79%\n",
      "[ 2941, 3430)   0   0.00%  95.79%\n",
      "[ 3430, 3920)   0   0.00%  95.79%\n",
      "[ 3920, 4409)   2   0.56%  96.35%\n",
      "[ 4409, 4899)   1   0.28%  96.63%\n",
      "[ 4899, 5388)   0   0.00%  96.63%\n",
      "[ 5388, 5877)   0   0.00%  96.63%\n",
      "[ 5877, 6367)   0   0.00%  96.63%\n",
      "[ 6367, 6856)   0   0.00%  96.63%\n",
      "[ 6856, 7346)   3   0.84%  97.47%\n",
      "[ 7346, 7835)   1   0.28%  97.75%\n",
      "[ 7835, 8324)   0   0.00%  97.75%\n",
      "[ 8324, 8814)   0   0.00%  97.75%\n",
      "[ 8814, 9303)   4   1.12%  98.88%\n",
      "[ 9303, 9792]   4   1.12% 100.00%\n",
      "\n",
      "Attribute in nodes:\n",
      "\t33 : f_8 [NUMERICAL]\n",
      "\t27 : f_4 [NUMERICAL]\n",
      "\t25 : f_24 [NUMERICAL]\n",
      "\t21 : f_9 [NUMERICAL]\n",
      "\t21 : f_16 [NUMERICAL]\n",
      "\t19 : f_20 [NUMERICAL]\n",
      "\t18 : f_21 [NUMERICAL]\n",
      "\t17 : f_25 [NUMERICAL]\n",
      "\t17 : f_18 [NUMERICAL]\n",
      "\t16 : f_22 [NUMERICAL]\n",
      "\t15 : f_6 [NUMERICAL]\n",
      "\t14 : f_23 [NUMERICAL]\n",
      "\t13 : f_17 [NUMERICAL]\n",
      "\t13 : f_10 [NUMERICAL]\n",
      "\t11 : f_5 [NUMERICAL]\n",
      "\t11 : f_3 [NUMERICAL]\n",
      "\t11 : f_19 [NUMERICAL]\n",
      "\t10 : f_2 [NUMERICAL]\n",
      "\t8 : f_14 [NUMERICAL]\n",
      "\t5 : f_7 [NUMERICAL]\n",
      "\t4 : f_13 [NUMERICAL]\n",
      "\t4 : f_12 [NUMERICAL]\n",
      "\t4 : f_11 [NUMERICAL]\n",
      "\t2 : f_15 [NUMERICAL]\n",
      "\t2 : f_1 [NUMERICAL]\n",
      "\n",
      "Attribute in nodes with depth <= 0:\n",
      "\t12 : f_4 [NUMERICAL]\n",
      "\t1 : f_8 [NUMERICAL]\n",
      "\t1 : f_3 [NUMERICAL]\n",
      "\t1 : f_14 [NUMERICAL]\n",
      "\n",
      "Attribute in nodes with depth <= 1:\n",
      "\t12 : f_4 [NUMERICAL]\n",
      "\t6 : f_8 [NUMERICAL]\n",
      "\t6 : f_25 [NUMERICAL]\n",
      "\t4 : f_17 [NUMERICAL]\n",
      "\t3 : f_10 [NUMERICAL]\n",
      "\t2 : f_9 [NUMERICAL]\n",
      "\t2 : f_7 [NUMERICAL]\n",
      "\t2 : f_24 [NUMERICAL]\n",
      "\t2 : f_23 [NUMERICAL]\n",
      "\t2 : f_22 [NUMERICAL]\n",
      "\t1 : f_3 [NUMERICAL]\n",
      "\t1 : f_16 [NUMERICAL]\n",
      "\t1 : f_14 [NUMERICAL]\n",
      "\n",
      "Attribute in nodes with depth <= 2:\n",
      "\t13 : f_8 [NUMERICAL]\n",
      "\t13 : f_4 [NUMERICAL]\n",
      "\t9 : f_24 [NUMERICAL]\n",
      "\t8 : f_17 [NUMERICAL]\n",
      "\t7 : f_25 [NUMERICAL]\n",
      "\t7 : f_21 [NUMERICAL]\n",
      "\t7 : f_16 [NUMERICAL]\n",
      "\t6 : f_9 [NUMERICAL]\n",
      "\t4 : f_23 [NUMERICAL]\n",
      "\t4 : f_10 [NUMERICAL]\n",
      "\t3 : f_7 [NUMERICAL]\n",
      "\t3 : f_6 [NUMERICAL]\n",
      "\t3 : f_22 [NUMERICAL]\n",
      "\t3 : f_20 [NUMERICAL]\n",
      "\t2 : f_5 [NUMERICAL]\n",
      "\t2 : f_3 [NUMERICAL]\n",
      "\t2 : f_2 [NUMERICAL]\n",
      "\t2 : f_18 [NUMERICAL]\n",
      "\t1 : f_19 [NUMERICAL]\n",
      "\t1 : f_14 [NUMERICAL]\n",
      "\n",
      "Attribute in nodes with depth <= 3:\n",
      "\t18 : f_8 [NUMERICAL]\n",
      "\t17 : f_4 [NUMERICAL]\n",
      "\t16 : f_24 [NUMERICAL]\n",
      "\t15 : f_16 [NUMERICAL]\n",
      "\t14 : f_9 [NUMERICAL]\n",
      "\t11 : f_6 [NUMERICAL]\n",
      "\t11 : f_3 [NUMERICAL]\n",
      "\t11 : f_22 [NUMERICAL]\n",
      "\t9 : f_25 [NUMERICAL]\n",
      "\t9 : f_21 [NUMERICAL]\n",
      "\t8 : f_20 [NUMERICAL]\n",
      "\t8 : f_2 [NUMERICAL]\n",
      "\t8 : f_18 [NUMERICAL]\n",
      "\t8 : f_17 [NUMERICAL]\n",
      "\t7 : f_5 [NUMERICAL]\n",
      "\t7 : f_10 [NUMERICAL]\n",
      "\t4 : f_7 [NUMERICAL]\n",
      "\t4 : f_23 [NUMERICAL]\n",
      "\t3 : f_19 [NUMERICAL]\n",
      "\t3 : f_14 [NUMERICAL]\n",
      "\t3 : f_12 [NUMERICAL]\n",
      "\n",
      "Attribute in nodes with depth <= 5:\n",
      "\t33 : f_8 [NUMERICAL]\n",
      "\t27 : f_4 [NUMERICAL]\n",
      "\t25 : f_24 [NUMERICAL]\n",
      "\t21 : f_9 [NUMERICAL]\n",
      "\t21 : f_16 [NUMERICAL]\n",
      "\t19 : f_20 [NUMERICAL]\n",
      "\t18 : f_21 [NUMERICAL]\n",
      "\t17 : f_25 [NUMERICAL]\n",
      "\t17 : f_18 [NUMERICAL]\n",
      "\t16 : f_22 [NUMERICAL]\n",
      "\t15 : f_6 [NUMERICAL]\n",
      "\t14 : f_23 [NUMERICAL]\n",
      "\t13 : f_17 [NUMERICAL]\n",
      "\t13 : f_10 [NUMERICAL]\n",
      "\t11 : f_5 [NUMERICAL]\n",
      "\t11 : f_3 [NUMERICAL]\n",
      "\t11 : f_19 [NUMERICAL]\n",
      "\t10 : f_2 [NUMERICAL]\n",
      "\t8 : f_14 [NUMERICAL]\n",
      "\t5 : f_7 [NUMERICAL]\n",
      "\t4 : f_13 [NUMERICAL]\n",
      "\t4 : f_12 [NUMERICAL]\n",
      "\t4 : f_11 [NUMERICAL]\n",
      "\t2 : f_15 [NUMERICAL]\n",
      "\t2 : f_1 [NUMERICAL]\n",
      "\n",
      "Condition type in nodes:\n",
      "\t341 : HigherCondition\n",
      "Condition type in nodes with depth <= 0:\n",
      "\t15 : HigherCondition\n",
      "Condition type in nodes with depth <= 1:\n",
      "\t44 : HigherCondition\n",
      "Condition type in nodes with depth <= 2:\n",
      "\t100 : HigherCondition\n",
      "Condition type in nodes with depth <= 3:\n",
      "\t194 : HigherCondition\n",
      "Condition type in nodes with depth <= 5:\n",
      "\t341 : HigherCondition\n",
      "\n"
     ]
    }
   ],
   "source": [
    "model_8.summary()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "keras-env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.9"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "0176d8e07f50d6f9d41e4d247411e051f24b378f20831339424b9cbb80e86332"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
