{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Build, Train and evaluate models with tensorflow decision forests\n",
    "\n",
    "Decision Forests (df) are a large family of machine learning algorithms for superivsed classification, regression and ranking. They use decision trees as a building block.\n",
    "\n",
    "today the two most popular df algorithms are random forests and gradient boosted decision trees. Both are ensemble tecniques that use multiple decision trees, but differ on how they do it\n",
    "\n",
    "In this tutorial, you will learn how to:\n",
    "\n",
    "1. Train a binary classification Random Forest on a dataset containing numerical, categorical  and missing features.\n",
    "2. Evaluate the model on a test dataset.\n",
    "3. Prepare the model for TensorFlow Serving.\n",
    "4. Examine the overall structure of the model and the importance of each feature.\n",
    "5. Re-train the model with a different learning algorithm (Gradient Boosted Decision Trees).\n",
    "6. Use a different set of input features.\n",
    "7. Change the hyperparameters of the model.\n",
    "8. Preprocess the features.\n",
    "9. Train a model for regression.\n",
    "10. Train a model for ranking.\n",
    "\n",
    "url: https://www.tensorflow.org/decision_forests/tutorials/beginner_colab"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow_decision_forests as tfdf\n",
    "\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found tensorflow df v1.0.1\n"
     ]
    }
   ],
   "source": [
    "# check version of the tensorflow df\n",
    "print(\"Found tensorflow df v\" + tfdf.__version__)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training a Random Forest Model\n",
    "\n",
    "We will train, evaluate, analyse and export binary classification Random Forest trained on the palmer penquins dataset\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load the dataset and convert it in a tf.dataset\n",
    "\n",
    "This dataset is small and stored as a csv-like file\n",
    "\n",
    "Lets assemble the dataset into a csv file and load it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>species</th>\n",
       "      <th>island</th>\n",
       "      <th>bill_length_mm</th>\n",
       "      <th>bill_depth_mm</th>\n",
       "      <th>flipper_length_mm</th>\n",
       "      <th>body_mass_g</th>\n",
       "      <th>sex</th>\n",
       "      <th>year</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Adelie</td>\n",
       "      <td>Torgersen</td>\n",
       "      <td>39.1</td>\n",
       "      <td>18.7</td>\n",
       "      <td>181.0</td>\n",
       "      <td>3750.0</td>\n",
       "      <td>male</td>\n",
       "      <td>2007</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Adelie</td>\n",
       "      <td>Torgersen</td>\n",
       "      <td>39.5</td>\n",
       "      <td>17.4</td>\n",
       "      <td>186.0</td>\n",
       "      <td>3800.0</td>\n",
       "      <td>female</td>\n",
       "      <td>2007</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Adelie</td>\n",
       "      <td>Torgersen</td>\n",
       "      <td>40.3</td>\n",
       "      <td>18.0</td>\n",
       "      <td>195.0</td>\n",
       "      <td>3250.0</td>\n",
       "      <td>female</td>\n",
       "      <td>2007</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  species     island  bill_length_mm  bill_depth_mm  flipper_length_mm  \\\n",
       "0  Adelie  Torgersen            39.1           18.7              181.0   \n",
       "1  Adelie  Torgersen            39.5           17.4              186.0   \n",
       "2  Adelie  Torgersen            40.3           18.0              195.0   \n",
       "\n",
       "   body_mass_g     sex  year  \n",
       "0       3750.0    male  2007  \n",
       "1       3800.0  female  2007  \n",
       "2       3250.0  female  2007  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# load a dataset into pandas dataframe\n",
    "fname = \"../../dataset/penguins.csv\"\n",
    "dataset_df = pd.read_csv(fname)\n",
    "\n",
    "# display the first 3 examples\n",
    "dataset_df.head(3)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dataset conatain a mix of numerical (bill_depth_mm), categorical (island) and missing features.\n",
    "\n",
    "TFDF supports all these feature types natively (differently than nn based models), therefore there is no need to preprocess in the form of one-hot encoding, normalization or extra is_present feature.\n",
    "\n",
    "labels are a bit different. Keras metrics expect inegers. The label (species) is stored as a string so lets convert it into a integer "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Encode the categorical labels as integers\n",
    "\n",
    "This stage is necessary if your classification label is represented as a string since keras expect integer classification labels.\n",
    "\n",
    "When using pd_dataframe_to_tf_dataset, this step can be skipped"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "label classes: ['Adelie', 'Gentoo', 'Chinstrap']\n"
     ]
    }
   ],
   "source": [
    "# name of the label column\n",
    "label = \"species\"\n",
    "\n",
    "classes = dataset_df[label].unique().tolist()\n",
    "print(f\"label classes: {classes}\")\n",
    "\n",
    "dataset_df[label] = dataset_df[label].map(classes.index)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "split the dataset into training and testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "236 examples in training, 108 examples for testing\n"
     ]
    }
   ],
   "source": [
    "# split the dataset into a training and testing dataset\n",
    "\n",
    "def split_dataset(dataset, test_ratio=0.30):\n",
    "    \"\"\"Split a panda dataframe in two\"\"\"\n",
    "    test_indices = np.random.rand(len(dataset)) < test_ratio\n",
    "    return dataset[~test_indices], dataset[test_indices]\n",
    "\n",
    "train_ds_pd, test_ds_pd = split_dataset(dataset_df)\n",
    "print(\"{} examples in training, {} examples for testing\" .format(\n",
    "    len(train_ds_pd), len(test_ds_pd)\n",
    "))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally convert the pandas dataframe (pd.dataframe) into tensorflow datasets (tf.data.dataset)\n",
    "\n",
    "Notes: Recall that pd_dataframe_to_tf_dataset converts string labels to integers if necessary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Metal device set to: Apple M1\n",
      "\n",
      "systemMemory: 8.00 GB\n",
      "maxCacheSize: 2.67 GB\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/eric/keras-env/lib/python3.8/site-packages/tensorflow_decision_forests/keras/core_inference.py:873: FutureWarning: In a future version of pandas all arguments of DataFrame.drop except for the argument 'labels' will be keyword-only.\n",
      "  features_dataframe = dataframe.drop(label, 1)\n",
      "2022-12-22 20:55:52.570550: I tensorflow/core/common_runtime/pluggable_device/pluggable_device_factory.cc:306] Could not identify NUMA node of platform GPU ID 0, defaulting to 0. Your kernel may not have been built with NUMA support.\n",
      "2022-12-22 20:55:52.572158: I tensorflow/core/common_runtime/pluggable_device/pluggable_device_factory.cc:272] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 0 MB memory) -> physical PluggableDevice (device: 0, name: METAL, pci bus id: <undefined>)\n",
      "/Users/eric/keras-env/lib/python3.8/site-packages/tensorflow_decision_forests/keras/core_inference.py:873: FutureWarning: In a future version of pandas all arguments of DataFrame.drop except for the argument 'labels' will be keyword-only.\n",
      "  features_dataframe = dataframe.drop(label, 1)\n"
     ]
    }
   ],
   "source": [
    "train_ds = tfdf.keras.pd_dataframe_to_tf_dataset(train_ds_pd, label=label)\n",
    "test_ds = tfdf.keras.pd_dataframe_to_tf_dataset(test_ds_pd, label=label)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "if you want to create the tf.data.dataset yourself, there are couple of things to remember:\n",
    "- the learning algorithms work with a one-epoch dataset and without shuffling\n",
    "- The batch size does not impact the training algorithm, but a small value might slow down reading the dataset"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Use 8 thread(s) for training\n",
      "Use /var/folders/sk/f7k402kx1wvdmcz91gdz6hs00000gn/T/tmp5bvbu0oq as temporary training directory\n",
      "Reading training dataset...\n",
      "Training tensor examples:\n",
      "Features: {'island': <tf.Tensor 'data_4:0' shape=(None,) dtype=string>, 'bill_length_mm': <tf.Tensor 'data_1:0' shape=(None,) dtype=float64>, 'bill_depth_mm': <tf.Tensor 'data:0' shape=(None,) dtype=float64>, 'flipper_length_mm': <tf.Tensor 'data_3:0' shape=(None,) dtype=float64>, 'body_mass_g': <tf.Tensor 'data_2:0' shape=(None,) dtype=float64>, 'sex': <tf.Tensor 'data_5:0' shape=(None,) dtype=string>, 'year': <tf.Tensor 'data_6:0' shape=(None,) dtype=int64>}\n",
      "Label: Tensor(\"data_7:0\", shape=(None,), dtype=int64)\n",
      "Weights: None\n",
      "Normalized tensor features:\n",
      " {'island': SemanticTensor(semantic=<Semantic.CATEGORICAL: 2>, tensor=<tf.Tensor 'data_4:0' shape=(None,) dtype=string>), 'bill_length_mm': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'Cast:0' shape=(None,) dtype=float32>), 'bill_depth_mm': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'Cast_1:0' shape=(None,) dtype=float32>), 'flipper_length_mm': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'Cast_2:0' shape=(None,) dtype=float32>), 'body_mass_g': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'Cast_3:0' shape=(None,) dtype=float32>), 'sex': SemanticTensor(semantic=<Semantic.CATEGORICAL: 2>, tensor=<tf.Tensor 'data_5:0' shape=(None,) dtype=string>), 'year': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'Cast_4:0' shape=(None,) dtype=float32>)}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-12-22 21:01:20.666251: W tensorflow/core/platform/profile_utils/cpu_utils.cc:128] Failed to get CPU frequency: 0 Hz\n",
      "2022-12-22 21:01:20.667602: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:114] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training dataset read in 0:00:02.064181. Found 236 examples.\n",
      "Training model...\n",
      "Standard output detected as not visible to the user e.g. running in a notebook. Creating a training log redirection. If training get stuck, try calling tfdf.keras.set_training_logs_redirection(False).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[INFO kernel.cc:813] Start Yggdrasil model training\n",
      "[INFO kernel.cc:814] Collect training examples\n",
      "[INFO kernel.cc:422] Number of batches: 1\n",
      "[INFO kernel.cc:423] Number of examples: 236\n",
      "[INFO kernel.cc:836] Training dataset:\n",
      "Number of records: 236\n",
      "Number of columns: 8\n",
      "\n",
      "Number of columns by type:\n",
      "\tNUMERICAL: 5 (62.5%)\n",
      "\tCATEGORICAL: 3 (37.5%)\n",
      "\n",
      "Columns:\n",
      "\n",
      "NUMERICAL: 5 (62.5%)\n",
      "\t0: \"bill_depth_mm\" NUMERICAL num-nas:1 (0.423729%) mean:17.1706 min:13.1 max:21.5 sd:2.01451\n",
      "\t1: \"bill_length_mm\" NUMERICAL num-nas:1 (0.423729%) mean:43.9362 min:32.1 max:58 sd:5.45471\n",
      "\t2: \"body_mass_g\" NUMERICAL num-nas:1 (0.423729%) mean:4177.02 min:2700 max:6000 sd:770.551\n",
      "\t3: \"flipper_length_mm\" NUMERICAL num-nas:1 (0.423729%) mean:200.745 min:174 max:230 sd:13.4213\n",
      "\t6: \"year\" NUMERICAL mean:2008.01 min:2007 max:2009 sd:0.820711\n",
      "\n",
      "CATEGORICAL: 3 (37.5%)\n",
      "\t4: \"island\" CATEGORICAL has-dict vocab-size:4 zero-ood-items most-frequent:\"Biscoe\" 103 (43.6441%)\n",
      "\t5: \"sex\" CATEGORICAL num-nas:7 (2.9661%) has-dict vocab-size:3 zero-ood-items most-frequent:\"female\" 120 (52.4017%)\n",
      "\t7: \"__LABEL\" CATEGORICAL integerized vocab-size:4 no-ood-item\n",
      "\n",
      "Terminology:\n",
      "\tnas: Number of non-available (i.e. missing) values.\n",
      "\tood: Out of dictionary.\n",
      "\tmanually-defined: Attribute which type is manually defined by the user i.e. the type was not automatically inferred.\n",
      "\ttokenized: The attribute value is obtained through tokenization.\n",
      "\thas-dict: The attribute is attached to a string dictionary e.g. a categorical attribute stored as a string.\n",
      "\tvocab-size: Number of unique values.\n",
      "\n",
      "[INFO kernel.cc:882] Configure learner\n",
      "[INFO kernel.cc:912] Training config:\n",
      "learner: \"RANDOM_FOREST\"\n",
      "features: \"bill_depth_mm\"\n",
      "features: \"bill_length_mm\"\n",
      "features: \"body_mass_g\"\n",
      "features: \"flipper_length_mm\"\n",
      "features: \"island\"\n",
      "features: \"sex\"\n",
      "features: \"year\"\n",
      "label: \"__LABEL\"\n",
      "task: CLASSIFICATION\n",
      "random_seed: 123456\n",
      "metadata {\n",
      "  framework: \"TF Keras\"\n",
      "}\n",
      "pure_serving_model: false\n",
      "[yggdrasil_decision_forests.model.random_forest.proto.random_forest_config] {\n",
      "  num_trees: 300\n",
      "  decision_tree {\n",
      "    max_depth: 16\n",
      "    min_examples: 5\n",
      "    in_split_min_examples_check: true\n",
      "    keep_non_leaf_label_distribution: true\n",
      "    num_candidate_attributes: 0\n",
      "    missing_value_policy: GLOBAL_IMPUTATION\n",
      "    allow_na_conditions: false\n",
      "    categorical_set_greedy_forward {\n",
      "      sampling: 0.1\n",
      "      max_num_items: -1\n",
      "      min_item_frequency: 1\n",
      "    }\n",
      "    growing_strategy_local {\n",
      "    }\n",
      "    categorical {\n",
      "      cart {\n",
      "      }\n",
      "    }\n",
      "    axis_aligned_split {\n",
      "    }\n",
      "    internal {\n",
      "      sorting_strategy: PRESORTED\n",
      "    }\n",
      "    uplift {\n",
      "      min_examples_in_treatment: 5\n",
      "      split_score: KULLBACK_LEIBLER\n",
      "    }\n",
      "  }\n",
      "  winner_take_all_inference: true\n",
      "  compute_oob_performances: true\n",
      "  compute_oob_variable_importances: false\n",
      "  num_oob_variable_importances_permutations: 1\n",
      "  bootstrap_training_dataset: true\n",
      "  bootstrap_size_ratio: 1\n",
      "  adapt_bootstrap_size_ratio_for_maximum_training_duration: false\n",
      "  sampling_with_replacement: true\n",
      "}\n",
      "\n",
      "[INFO kernel.cc:915] Deployment config:\n",
      "cache_path: \"/var/folders/sk/f7k402kx1wvdmcz91gdz6hs00000gn/T/tmp5bvbu0oq/working_cache\"\n",
      "num_threads: 8\n",
      "try_resume_training: true\n",
      "\n",
      "[INFO kernel.cc:944] Train model\n",
      "[INFO random_forest.cc:407] Training random forest on 236 example(s) and 7 feature(s).\n",
      "[INFO random_forest.cc:796] Training of tree  1/300 (tree index:7) done accuracy:0.963855 logloss:1.30278\n",
      "[INFO random_forest.cc:796] Training of tree  13/300 (tree index:12) done accuracy:0.974249 logloss:0.215154\n",
      "[INFO random_forest.cc:796] Training of tree  25/300 (tree index:24) done accuracy:0.966102 logloss:0.23798\n",
      "[INFO random_forest.cc:796] Training of tree  37/300 (tree index:36) done accuracy:0.961864 logloss:0.239533\n",
      "[INFO random_forest.cc:796] Training of tree  47/300 (tree index:46) done accuracy:0.970339 logloss:0.233952\n",
      "[INFO random_forest.cc:796] Training of tree  57/300 (tree index:57) done accuracy:0.966102 logloss:0.231234\n",
      "[INFO random_forest.cc:796] Training of tree  67/300 (tree index:64) done accuracy:0.966102 logloss:0.232442\n",
      "[INFO random_forest.cc:796] Training of tree  77/300 (tree index:74) done accuracy:0.966102 logloss:0.228661\n",
      "[INFO random_forest.cc:796] Training of tree  87/300 (tree index:88) done accuracy:0.970339 logloss:0.227184\n",
      "[INFO random_forest.cc:796] Training of tree  97/300 (tree index:97) done accuracy:0.970339 logloss:0.227377\n",
      "[INFO random_forest.cc:796] Training of tree  107/300 (tree index:109) done accuracy:0.978814 logloss:0.225878\n",
      "[INFO random_forest.cc:796] Training of tree  117/300 (tree index:113) done accuracy:0.978814 logloss:0.227102\n",
      "[INFO random_forest.cc:796] Training of tree  127/300 (tree index:127) done accuracy:0.978814 logloss:0.225821\n",
      "[INFO random_forest.cc:796] Training of tree  138/300 (tree index:138) done accuracy:0.978814 logloss:0.22631\n",
      "[INFO random_forest.cc:796] Training of tree  148/300 (tree index:147) done accuracy:0.978814 logloss:0.227489\n",
      "[INFO random_forest.cc:796] Training of tree  158/300 (tree index:158) done accuracy:0.978814 logloss:0.226898\n",
      "[INFO random_forest.cc:796] Training of tree  168/300 (tree index:169) done accuracy:0.978814 logloss:0.227407\n",
      "[INFO random_forest.cc:796] Training of tree  178/300 (tree index:174) done accuracy:0.974576 logloss:0.228244\n",
      "[INFO random_forest.cc:796] Training of tree  188/300 (tree index:188) done accuracy:0.974576 logloss:0.228669\n",
      "[INFO random_forest.cc:796] Training of tree  198/300 (tree index:198) done accuracy:0.974576 logloss:0.228337\n",
      "[INFO random_forest.cc:796] Training of tree  208/300 (tree index:207) done accuracy:0.974576 logloss:0.228553\n",
      "[INFO random_forest.cc:796] Training of tree  218/300 (tree index:219) done accuracy:0.974576 logloss:0.229343\n",
      "[INFO random_forest.cc:796] Training of tree  228/300 (tree index:229) done accuracy:0.974576 logloss:0.229109\n",
      "[INFO random_forest.cc:796] Training of tree  238/300 (tree index:240) done accuracy:0.974576 logloss:0.229104\n",
      "[INFO random_forest.cc:796] Training of tree  248/300 (tree index:248) done accuracy:0.974576 logloss:0.229143\n",
      "[INFO random_forest.cc:796] Training of tree  258/300 (tree index:252) done accuracy:0.974576 logloss:0.228786\n",
      "[INFO random_forest.cc:796] Training of tree  270/300 (tree index:270) done accuracy:0.970339 logloss:0.2294\n",
      "[INFO random_forest.cc:796] Training of tree  280/300 (tree index:280) done accuracy:0.974576 logloss:0.229427\n",
      "[INFO random_forest.cc:796] Training of tree  290/300 (tree index:287) done accuracy:0.974576 logloss:0.229723\n",
      "[INFO random_forest.cc:796] Training of tree  300/300 (tree index:297) done accuracy:0.974576 logloss:0.230239\n",
      "[INFO random_forest.cc:876] Final OOB metrics: accuracy:0.974576 logloss:0.230239\n",
      "[INFO kernel.cc:961] Export model in log directory: /var/folders/sk/f7k402kx1wvdmcz91gdz6hs00000gn/T/tmp5bvbu0oq with prefix c2615c0d76ab46fb\n",
      "[INFO kernel.cc:978] Save model in resources\n",
      "[INFO kernel.cc:1176] Loading model from path /var/folders/sk/f7k402kx1wvdmcz91gdz6hs00000gn/T/tmp5bvbu0oq/model/ with prefix c2615c0d76ab46fb\n",
      "[INFO decision_forest.cc:639] Model loaded with 300 root(s), 4178 node(s), and 7 input feature(s).\n",
      "[INFO abstract_model.cc:1249] Engine \"RandomForestGeneric\" built\n",
      "[INFO kernel.cc:1022] Use fast generic engine\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model trained in 0:00:00.088352\n",
      "Compiling model...\n",
      "WARNING:tensorflow:AutoGraph could not transform <function simple_ml_inference_op_with_handle at 0x17da1cca0> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: could not get source code\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:AutoGraph could not transform <function simple_ml_inference_op_with_handle at 0x17da1cca0> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: could not get source code\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING: AutoGraph could not transform <function simple_ml_inference_op_with_handle at 0x17da1cca0> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: could not get source code\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "Model compiled.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-12-22 21:01:21.678108: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:114] Plugin optimizer for device_type GPU is enabled.\n",
      "2022-12-22 21:01:21.730975: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:114] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x17dc29d90>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# specify the model\n",
    "model_1 = tfdf.keras.RandomForestModel(verbose=2)\n",
    "\n",
    "# train the model\n",
    "model_1.fit(x=train_ds)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Remarks\n",
    "\n",
    "- No input featuers are specified. Therefore all the columsn will be used as input features expect for the label. The feature used by the model are shown in the training logs and in the model.summary()\n",
    "- df consume natively numerical, categorical, categorical-set features and missing-value. Numerical features do not need to be normalized. Categorical strings values do not need to be encoded in a dictionary\n",
    "- No training hyper parameters are specified. Therefore the default hyper-parameters will be used. Default hyper-parameters provide reasonable results in most situations\n",
    "- Calling compile on the model before fit is optional. Compile can be used to provide extra evaluation metrics\n",
    "- training algorithms do not need validation datatsets. If validation dataset is provided, it will not only be used to show metrics \n",
    "- tweak the verbose argument to radnomforestmodel to control the amount of displayed training logs. Set verbose=0 to hide most of the logs. Set verbose=2 to show all the logs"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluate the model\n",
    "\n",
    "Lets evaluate our model on the test dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 321ms/step - loss: 0.0000e+00 - accuracy: 0.9815\n",
      "\n",
      "loss: 0.0000\n",
      "accuracy: 0.9815\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-12-22 21:10:07.063254: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:114] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    }
   ],
   "source": [
    "model_1.compile(metrics=[\"accuracy\"])\n",
    "evaluation = model_1.evaluate(test_ds, return_dict=True)\n",
    "print()\n",
    "\n",
    "for name, value in evaluation.items():\n",
    "    print(f\"{name}: {value:.4f}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "keras-env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.9"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "0176d8e07f50d6f9d41e4d247411e051f24b378f20831339424b9cbb80e86332"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
