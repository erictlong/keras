{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imbalanced classification: Credit card Fraud Detection\n",
    "\n",
    "Example looking into the credit card fraud detection dataset \n",
    "to demonstrate how to train a classification model with highly imbalanced classes\n",
    "\n",
    "url: \n",
    "https://keras.io/examples/structured_data/imbalanced_classification/\n",
    "\n",
    "dataset:\n",
    "https://www.kaggle.com/mlg-ulb/creditcardfraud/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "header: \"Time\",\"V1\",\"V2\",\"V3\",\"V4\",\"V5\",\"V6\",\"V7\",\"V8\",\"V9\",\"V10\",\"V11\",\"V12\",\"V13\",\"V14\",\"V15\",\"V16\",\"V17\",\"V18\",\"V19\",\"V20\",\"V21\",\"V22\",\"V23\",\"V24\",\"V25\",\"V26\",\"V27\",\"V28\",\"Amount\",\"Class\"\n",
      "example features: [0.0, -1.3598071336738, -0.0727811733098497, 2.53634673796914, 1.37815522427443, -0.338320769942518, 0.462387777762292, 0.239598554061257, 0.0986979012610507, 0.363786969611213, 0.0907941719789316, -0.551599533260813, -0.617800855762348, -0.991389847235408, -0.311169353699879, 1.46817697209427, -0.470400525259478, 0.207971241929242, 0.0257905801985591, 0.403992960255733, 0.251412098239705, -0.018306777944153, 0.277837575558899, -0.110473910188767, 0.0669280749146731, 0.128539358273528, -0.189114843888824, 0.133558376740387, -0.0210530534538215, 149.62]\n",
      "features.shape: (284807, 30)\n",
      "targets.shape: (284807, 1)\n"
     ]
    }
   ],
   "source": [
    "import csv\n",
    "import numpy as np\n",
    "\n",
    "fname = \"../dataset/creditcard.csv\"\n",
    "\n",
    "all_features = []\n",
    "all_targets = []\n",
    "\n",
    "with open(fname) as f:\n",
    "    for i, line in enumerate(f):\n",
    "        if i == 0:\n",
    "            print(\"header:\", line.strip())\n",
    "            continue # skip the header\n",
    "        fields = line.strip().split(\",\")\n",
    "        all_features.append([float(v.replace('\"', \"\")) for v in fields[:-1]])\n",
    "        all_targets.append([int(fields[-1].replace('\"', \"\"))])\n",
    "        if i == 1:\n",
    "            print(\"example features:\", all_features[-1])\n",
    "\n",
    "features = np.array(all_features, dtype=\"float32\")\n",
    "targets = np.array(all_targets, dtype=\"uint8\")\n",
    "print(\"features.shape:\", features.shape)\n",
    "print(\"targets.shape:\", targets.shape)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prepare a validation set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of training samples: 227846\n",
      "number of validation samples: 56961\n"
     ]
    }
   ],
   "source": [
    "num_val_samples = int(len(features) * 0.2)\n",
    "train_features = features[:-num_val_samples]\n",
    "train_targets = targets[:-num_val_samples]\n",
    "val_features = features[-num_val_samples:]\n",
    "val_targets = targets[-num_val_samples:]\n",
    "\n",
    "print(\"number of training samples:\", len(train_features))\n",
    "print(\"number of validation samples:\", len(val_features))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Analyze class imbalance in the targets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of postive samples in training data: 417 (0.18% of total)\n"
     ]
    }
   ],
   "source": [
    "counts = np.bincount(train_targets[:, 0])\n",
    "\n",
    "print(\n",
    "    \"number of postive samples in training data: {} ({:.2f}% of total)\".format(\n",
    "        counts[1], 100 * float(counts[1]) / len(train_targets)\n",
    "    )\n",
    ")\n",
    "\n",
    "weight_for_0 = 1.0 / counts[0]\n",
    "weight_for_1 = 1.0 / counts[1]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Normalize the data using training set statistics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "mean = np.mean(train_features, axis=0)\n",
    "train_features -= mean\n",
    "val_features -= mean\n",
    "std = np.std(train_features, axis=0)\n",
    "train_features /= std\n",
    "val_features /= std"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Build a binary classification model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Metal device set to: Apple M1\n",
      "\n",
      "systemMemory: 8.00 GB\n",
      "maxCacheSize: 2.67 GB\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-12-09 16:18:53.336464: I tensorflow/core/common_runtime/pluggable_device/pluggable_device_factory.cc:306] Could not identify NUMA node of platform GPU ID 0, defaulting to 0. Your kernel may not have been built with NUMA support.\n",
      "2022-12-09 16:18:53.337608: I tensorflow/core/common_runtime/pluggable_device/pluggable_device_factory.cc:272] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 0 MB memory) -> physical PluggableDevice (device: 0, name: METAL, pci bus id: <undefined>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense (Dense)               (None, 256)               7936      \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 256)               65792     \n",
      "                                                                 \n",
      " dropout (Dropout)           (None, 256)               0         \n",
      "                                                                 \n",
      " dense_2 (Dense)             (None, 256)               65792     \n",
      "                                                                 \n",
      " dropout_1 (Dropout)         (None, 256)               0         \n",
      "                                                                 \n",
      " dense_3 (Dense)             (None, 1)                 257       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 139,777\n",
      "Trainable params: 139,777\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "from tensorflow import keras\n",
    "\n",
    "model = keras.Sequential(\n",
    "    [\n",
    "        keras.layers.Dense(\n",
    "            256, activation=\"relu\", input_shape=(train_features.shape[-1],)\n",
    "        ),\n",
    "        keras.layers.Dense(256, activation=\"relu\"),\n",
    "        keras.layers.Dropout(0.3),\n",
    "        keras.layers.Dense(256, activation=\"relu\"),\n",
    "        keras.layers.Dropout(0.3),\n",
    "        keras.layers.Dense(1, activation=\"sigmoid\"),\n",
    "    ]\n",
    ")\n",
    "model.summary()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train the model with class_weight argument"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-12-09 16:25:42.719350: W tensorflow/core/platform/profile_utils/cpu_utils.cc:128] Failed to get CPU frequency: 0 Hz\n",
      "2022-12-09 16:25:43.240262: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:114] Plugin optimizer for device_type GPU is enabled.\n",
      "2022-12-09 16:25:47.436108: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:114] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "113/113 - 5s - loss: 2.4018e-06 - fn: 50.0000 - fp: 29164.0000 - tn: 198265.0000 - tp: 367.0000 - precision: 0.0124 - recall: 0.8801 - val_loss: 0.0922 - val_fn: 10.0000 - val_fp: 865.0000 - val_tn: 56021.0000 - val_tp: 65.0000 - val_precision: 0.0699 - val_recall: 0.8667 - 5s/epoch - 44ms/step\n",
      "Epoch 2/30\n",
      "113/113 - 2s - loss: 1.4385e-06 - fn: 29.0000 - fp: 7709.0000 - tn: 219720.0000 - tp: 388.0000 - precision: 0.0479 - recall: 0.9305 - val_loss: 0.1094 - val_fn: 9.0000 - val_fp: 988.0000 - val_tn: 55898.0000 - val_tp: 66.0000 - val_precision: 0.0626 - val_recall: 0.8800 - 2s/epoch - 14ms/step\n",
      "Epoch 3/30\n",
      "113/113 - 2s - loss: 1.5720e-06 - fn: 32.0000 - fp: 8826.0000 - tn: 218603.0000 - tp: 385.0000 - precision: 0.0418 - recall: 0.9233 - val_loss: 0.1296 - val_fn: 7.0000 - val_fp: 1560.0000 - val_tn: 55326.0000 - val_tp: 68.0000 - val_precision: 0.0418 - val_recall: 0.9067 - 2s/epoch - 14ms/step\n",
      "Epoch 4/30\n",
      "113/113 - 2s - loss: 1.3123e-06 - fn: 26.0000 - fp: 7685.0000 - tn: 219744.0000 - tp: 391.0000 - precision: 0.0484 - recall: 0.9376 - val_loss: 0.1114 - val_fn: 4.0000 - val_fp: 1834.0000 - val_tn: 55052.0000 - val_tp: 71.0000 - val_precision: 0.0373 - val_recall: 0.9467 - 2s/epoch - 14ms/step\n",
      "Epoch 5/30\n",
      "113/113 - 2s - loss: 9.0583e-07 - fn: 19.0000 - fp: 5761.0000 - tn: 221668.0000 - tp: 398.0000 - precision: 0.0646 - recall: 0.9544 - val_loss: 0.0346 - val_fn: 9.0000 - val_fp: 442.0000 - val_tn: 56444.0000 - val_tp: 66.0000 - val_precision: 0.1299 - val_recall: 0.8800 - 2s/epoch - 14ms/step\n",
      "Epoch 6/30\n",
      "113/113 - 2s - loss: 9.5970e-07 - fn: 18.0000 - fp: 5720.0000 - tn: 221709.0000 - tp: 399.0000 - precision: 0.0652 - recall: 0.9568 - val_loss: 0.0652 - val_fn: 7.0000 - val_fp: 996.0000 - val_tn: 55890.0000 - val_tp: 68.0000 - val_precision: 0.0639 - val_recall: 0.9067 - 2s/epoch - 13ms/step\n",
      "Epoch 7/30\n",
      "113/113 - 2s - loss: 6.7456e-07 - fn: 18.0000 - fp: 5971.0000 - tn: 221458.0000 - tp: 399.0000 - precision: 0.0626 - recall: 0.9568 - val_loss: 0.0279 - val_fn: 10.0000 - val_fp: 484.0000 - val_tn: 56402.0000 - val_tp: 65.0000 - val_precision: 0.1184 - val_recall: 0.8667 - 2s/epoch - 14ms/step\n",
      "Epoch 8/30\n",
      "113/113 - 2s - loss: 7.0809e-07 - fn: 16.0000 - fp: 6855.0000 - tn: 220574.0000 - tp: 401.0000 - precision: 0.0553 - recall: 0.9616 - val_loss: 0.0149 - val_fn: 13.0000 - val_fp: 282.0000 - val_tn: 56604.0000 - val_tp: 62.0000 - val_precision: 0.1802 - val_recall: 0.8267 - 2s/epoch - 15ms/step\n",
      "Epoch 9/30\n",
      "113/113 - 2s - loss: 8.7438e-07 - fn: 15.0000 - fp: 7118.0000 - tn: 220311.0000 - tp: 402.0000 - precision: 0.0535 - recall: 0.9640 - val_loss: 0.0311 - val_fn: 11.0000 - val_fp: 451.0000 - val_tn: 56435.0000 - val_tp: 64.0000 - val_precision: 0.1243 - val_recall: 0.8533 - 2s/epoch - 14ms/step\n",
      "Epoch 10/30\n",
      "113/113 - 1s - loss: 6.9742e-07 - fn: 13.0000 - fp: 5271.0000 - tn: 222158.0000 - tp: 404.0000 - precision: 0.0712 - recall: 0.9688 - val_loss: 0.0482 - val_fn: 10.0000 - val_fp: 478.0000 - val_tn: 56408.0000 - val_tp: 65.0000 - val_precision: 0.1197 - val_recall: 0.8667 - 1s/epoch - 13ms/step\n",
      "Epoch 11/30\n",
      "113/113 - 2s - loss: 5.8746e-07 - fn: 13.0000 - fp: 5405.0000 - tn: 222024.0000 - tp: 404.0000 - precision: 0.0695 - recall: 0.9688 - val_loss: 0.0403 - val_fn: 7.0000 - val_fp: 831.0000 - val_tn: 56055.0000 - val_tp: 68.0000 - val_precision: 0.0756 - val_recall: 0.9067 - 2s/epoch - 14ms/step\n",
      "Epoch 12/30\n",
      "113/113 - 2s - loss: 3.7167e-07 - fn: 5.0000 - fp: 3942.0000 - tn: 223487.0000 - tp: 412.0000 - precision: 0.0946 - recall: 0.9880 - val_loss: 0.0759 - val_fn: 7.0000 - val_fp: 2288.0000 - val_tn: 54598.0000 - val_tp: 68.0000 - val_precision: 0.0289 - val_recall: 0.9067 - 2s/epoch - 14ms/step\n",
      "Epoch 13/30\n",
      "113/113 - 2s - loss: 7.0741e-07 - fn: 10.0000 - fp: 6024.0000 - tn: 221405.0000 - tp: 407.0000 - precision: 0.0633 - recall: 0.9760 - val_loss: 0.0429 - val_fn: 8.0000 - val_fp: 842.0000 - val_tn: 56044.0000 - val_tp: 67.0000 - val_precision: 0.0737 - val_recall: 0.8933 - 2s/epoch - 14ms/step\n",
      "Epoch 14/30\n",
      "113/113 - 2s - loss: 5.5693e-07 - fn: 8.0000 - fp: 5281.0000 - tn: 222148.0000 - tp: 409.0000 - precision: 0.0719 - recall: 0.9808 - val_loss: 0.0179 - val_fn: 9.0000 - val_fp: 360.0000 - val_tn: 56526.0000 - val_tp: 66.0000 - val_precision: 0.1549 - val_recall: 0.8800 - 2s/epoch - 13ms/step\n",
      "Epoch 15/30\n",
      "113/113 - 1s - loss: 4.4946e-07 - fn: 8.0000 - fp: 4694.0000 - tn: 222735.0000 - tp: 409.0000 - precision: 0.0801 - recall: 0.9808 - val_loss: 0.0351 - val_fn: 7.0000 - val_fp: 821.0000 - val_tn: 56065.0000 - val_tp: 68.0000 - val_precision: 0.0765 - val_recall: 0.9067 - 1s/epoch - 13ms/step\n",
      "Epoch 16/30\n",
      "113/113 - 2s - loss: 3.7668e-07 - fn: 6.0000 - fp: 4734.0000 - tn: 222695.0000 - tp: 411.0000 - precision: 0.0799 - recall: 0.9856 - val_loss: 0.0436 - val_fn: 7.0000 - val_fp: 1240.0000 - val_tn: 55646.0000 - val_tp: 68.0000 - val_precision: 0.0520 - val_recall: 0.9067 - 2s/epoch - 14ms/step\n",
      "Epoch 17/30\n",
      "113/113 - 2s - loss: 3.3884e-07 - fn: 3.0000 - fp: 4320.0000 - tn: 223109.0000 - tp: 414.0000 - precision: 0.0875 - recall: 0.9928 - val_loss: 0.0333 - val_fn: 8.0000 - val_fp: 773.0000 - val_tn: 56113.0000 - val_tp: 67.0000 - val_precision: 0.0798 - val_recall: 0.8933 - 2s/epoch - 14ms/step\n",
      "Epoch 18/30\n",
      "113/113 - 2s - loss: 2.9904e-07 - fn: 4.0000 - fp: 3575.0000 - tn: 223854.0000 - tp: 413.0000 - precision: 0.1036 - recall: 0.9904 - val_loss: 0.0332 - val_fn: 9.0000 - val_fp: 720.0000 - val_tn: 56166.0000 - val_tp: 66.0000 - val_precision: 0.0840 - val_recall: 0.8800 - 2s/epoch - 14ms/step\n",
      "Epoch 19/30\n",
      "113/113 - 2s - loss: 8.2961e-07 - fn: 7.0000 - fp: 4430.0000 - tn: 222999.0000 - tp: 410.0000 - precision: 0.0847 - recall: 0.9832 - val_loss: 0.1062 - val_fn: 8.0000 - val_fp: 1317.0000 - val_tn: 55569.0000 - val_tp: 67.0000 - val_precision: 0.0484 - val_recall: 0.8933 - 2s/epoch - 14ms/step\n",
      "Epoch 20/30\n",
      "113/113 - 2s - loss: 8.4588e-07 - fn: 16.0000 - fp: 8762.0000 - tn: 218667.0000 - tp: 401.0000 - precision: 0.0438 - recall: 0.9616 - val_loss: 0.0470 - val_fn: 9.0000 - val_fp: 959.0000 - val_tn: 55927.0000 - val_tp: 66.0000 - val_precision: 0.0644 - val_recall: 0.8800 - 2s/epoch - 14ms/step\n",
      "Epoch 21/30\n",
      "113/113 - 2s - loss: 4.7340e-07 - fn: 9.0000 - fp: 5396.0000 - tn: 222033.0000 - tp: 408.0000 - precision: 0.0703 - recall: 0.9784 - val_loss: 0.1602 - val_fn: 6.0000 - val_fp: 2421.0000 - val_tn: 54465.0000 - val_tp: 69.0000 - val_precision: 0.0277 - val_recall: 0.9200 - 2s/epoch - 14ms/step\n",
      "Epoch 22/30\n",
      "113/113 - 2s - loss: 3.8700e-06 - fn: 10.0000 - fp: 6701.0000 - tn: 220728.0000 - tp: 407.0000 - precision: 0.0573 - recall: 0.9760 - val_loss: 0.0501 - val_fn: 13.0000 - val_fp: 216.0000 - val_tn: 56670.0000 - val_tp: 62.0000 - val_precision: 0.2230 - val_recall: 0.8267 - 2s/epoch - 13ms/step\n",
      "Epoch 23/30\n",
      "113/113 - 2s - loss: 9.6873e-07 - fn: 15.0000 - fp: 5022.0000 - tn: 222407.0000 - tp: 402.0000 - precision: 0.0741 - recall: 0.9640 - val_loss: 0.0317 - val_fn: 10.0000 - val_fp: 608.0000 - val_tn: 56278.0000 - val_tp: 65.0000 - val_precision: 0.0966 - val_recall: 0.8667 - 2s/epoch - 14ms/step\n",
      "Epoch 24/30\n",
      "113/113 - 2s - loss: 1.7430e-06 - fn: 13.0000 - fp: 6332.0000 - tn: 221097.0000 - tp: 404.0000 - precision: 0.0600 - recall: 0.9688 - val_loss: 0.0655 - val_fn: 11.0000 - val_fp: 483.0000 - val_tn: 56403.0000 - val_tp: 64.0000 - val_precision: 0.1170 - val_recall: 0.8533 - 2s/epoch - 14ms/step\n",
      "Epoch 25/30\n",
      "113/113 - 2s - loss: 2.9757e-06 - fn: 14.0000 - fp: 5508.0000 - tn: 221921.0000 - tp: 403.0000 - precision: 0.0682 - recall: 0.9664 - val_loss: 0.1261 - val_fn: 8.0000 - val_fp: 826.0000 - val_tn: 56060.0000 - val_tp: 67.0000 - val_precision: 0.0750 - val_recall: 0.8933 - 2s/epoch - 14ms/step\n",
      "Epoch 26/30\n",
      "113/113 - 1s - loss: 1.8949e-06 - fn: 11.0000 - fp: 4718.0000 - tn: 222711.0000 - tp: 406.0000 - precision: 0.0792 - recall: 0.9736 - val_loss: 0.0271 - val_fn: 11.0000 - val_fp: 332.0000 - val_tn: 56554.0000 - val_tp: 64.0000 - val_precision: 0.1616 - val_recall: 0.8533 - 1s/epoch - 13ms/step\n",
      "Epoch 27/30\n",
      "113/113 - 1s - loss: 5.1390e-07 - fn: 5.0000 - fp: 3660.0000 - tn: 223769.0000 - tp: 412.0000 - precision: 0.1012 - recall: 0.9880 - val_loss: 0.0349 - val_fn: 9.0000 - val_fp: 512.0000 - val_tn: 56374.0000 - val_tp: 66.0000 - val_precision: 0.1142 - val_recall: 0.8800 - 1s/epoch - 13ms/step\n",
      "Epoch 28/30\n",
      "113/113 - 1s - loss: 6.0068e-07 - fn: 5.0000 - fp: 3182.0000 - tn: 224247.0000 - tp: 412.0000 - precision: 0.1146 - recall: 0.9880 - val_loss: 0.0511 - val_fn: 9.0000 - val_fp: 718.0000 - val_tn: 56168.0000 - val_tp: 66.0000 - val_precision: 0.0842 - val_recall: 0.8800 - 1s/epoch - 13ms/step\n",
      "Epoch 29/30\n",
      "113/113 - 2s - loss: 1.5018e-06 - fn: 8.0000 - fp: 4518.0000 - tn: 222911.0000 - tp: 409.0000 - precision: 0.0830 - recall: 0.9808 - val_loss: 0.0230 - val_fn: 14.0000 - val_fp: 259.0000 - val_tn: 56627.0000 - val_tp: 61.0000 - val_precision: 0.1906 - val_recall: 0.8133 - 2s/epoch - 13ms/step\n",
      "Epoch 30/30\n",
      "113/113 - 2s - loss: 5.5724e-07 - fn: 5.0000 - fp: 2822.0000 - tn: 224607.0000 - tp: 412.0000 - precision: 0.1274 - recall: 0.9880 - val_loss: 0.0588 - val_fn: 9.0000 - val_fp: 874.0000 - val_tn: 56012.0000 - val_tp: 66.0000 - val_precision: 0.0702 - val_recall: 0.8800 - 2s/epoch - 14ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x291960f10>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metrics = [\n",
    "    keras.metrics.FalseNegatives(name=\"fn\"),\n",
    "    keras.metrics.FalsePositives(name=\"fp\"),\n",
    "    keras.metrics.TrueNegatives(name=\"tn\"),\n",
    "    keras.metrics.TruePositives(name=\"tp\"),\n",
    "    keras.metrics.Precision(name=\"precision\"),\n",
    "    keras.metrics.Recall(name=\"recall\"),\n",
    "]\n",
    "\n",
    "model.compile(\n",
    "    optimizer=keras.optimizers.Adam(1e-2), loss=\"binary_crossentropy\", metrics=metrics\n",
    ")\n",
    "\n",
    "callbacks = [keras.callbacks.ModelCheckpoint(\"fraud_model_at_epoch_{epoch}.h5\")]\n",
    "class_weight = {0: weight_for_0, 1: weight_for_1}\n",
    "\n",
    "model.fit(\n",
    "    train_features,\n",
    "    train_targets,\n",
    "    batch_size=2028,\n",
    "    epochs=30,\n",
    "    verbose=2,\n",
    "    callbacks=callbacks,\n",
    "    validation_data=(val_features, val_targets),\n",
    "    class_weight=class_weight,\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "keras-env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.9 (default, Jul 19 2021, 09:37:30) \n[Clang 13.0.0 (clang-1300.0.27.3)]"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "0176d8e07f50d6f9d41e4d247411e051f24b378f20831339424b9cbb80e86332"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
